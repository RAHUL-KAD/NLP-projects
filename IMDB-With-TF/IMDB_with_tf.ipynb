{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_embedding_using_TF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXbsZ2mp7YHs"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg5rUE_87EMR"
      },
      "source": [
        "import io # Input output operations\n",
        "import os # Operating system\n",
        "import shutil # TO perform high level file operations\n",
        "import string # to perform high level string operations\n",
        "import re # Regular expression\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJSQn4AN8l4b"
      },
      "source": [
        "## Downloding the dataset\n",
        "\n",
        "You will use the Large Movie Review Dataset through the tutorial. You will train a sentiment classifier model on this dataset and in the process learn embeddings from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_mhsh5N8jbd",
        "outputId": "a3db96cf-8a48-4701-ec3c-55103174f3a1"
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url, \n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdb.vocab', 'train', 'imdbEr.txt', 'README', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cet3--mm-UZM"
      },
      "source": [
        "Take a look at the train/ directory. It has pos and neg folders with movie reviews labelled as positive and negative respectively. You will use reviews from pos and neg folders to train a binary classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AviDMvNo9kTi",
        "outputId": "79fab929-95c9-4452-a10e-029290099316"
      },
      "source": [
        "# train dataset directory\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['urls_pos.txt',\n",
              " 'pos',\n",
              " 'labeledBow.feat',\n",
              " 'urls_neg.txt',\n",
              " 'neg',\n",
              " 'unsup',\n",
              " 'urls_unsup.txt',\n",
              " 'unsupBow.feat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kRPU4WD-3lL"
      },
      "source": [
        "#### train directory also has additioinal folders which should be removed before creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyCEwdkR-NLJ"
      },
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "\n",
        "shutil.rmtree(remove_dir)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-NZ-ubrANV1"
      },
      "source": [
        "Next, create a tf.data.Dataset using tf.keras.preprocessing.text_dataset_from_directory.\n",
        "\n",
        "Use the train directory to create both train and validation datasets with a split of 20% for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F6xgSLC_9NO",
        "outputId": "1d44e1ee-c4b1-4119-fbcd-c459f021aa9a"
      },
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size = batch_size, validation_split=0.2, \n",
        "    subset='training', seed=seed\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size = batch_size, validation_split=0.2, \n",
        "    subset='validation', seed=seed\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMMg4oVgCC47"
      },
      "source": [
        "Take a look at a few movie reviews and their labels (1: positive, 0: negative) from the train dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw-zrUMeBNok",
        "outputId": "c42d4555-d494-41ac-f785-661bc5447dd9"
      },
      "source": [
        "for text, label in train_dataset.take(1):\n",
        "  for i in range(5):\n",
        "    print(label[i].numpy(), text.numpy()[i])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 b\"Oh My God! Please, for the love of all that is holy, Do Not Watch This Movie! It it 82 minutes of my life I will never get back. Sure, I could have stopped watching half way through. But I thought it might get better. It Didn't. Anyone who actually enjoyed this movie is one seriously sick and twisted individual. No wonder us Australians/New Zealanders have a terrible reputation when it comes to making movies. Everything about this movie is horrible, from the acting to the editing. I don't even normally write reviews on here, but in this case I'll make an exception. I only wish someone had of warned me before I hired this catastrophe\"\n",
            "1 b'This movie is SOOOO funny!!! The acting is WONDERFUL, the Ramones are sexy, the jokes are subtle, and the plot is just what every high schooler dreams of doing to his/her school. I absolutely loved the soundtrack as well as the carefully placed cynicism. If you like monty python, You will love this film. This movie is a tad bit \"grease\"esk (without all the annoying songs). The songs that are sung are likable; you might even find yourself singing these songs once the movie is through. This musical ranks number two in musicals to me (second next to the blues brothers). But please, do not think of it as a musical per say; seeing as how the songs are so likable, it is hard to tell a carefully choreographed scene is taking place. I think of this movie as more of a comedy with undertones of romance. You will be reminded of what it was like to be a rebellious teenager; needless to say, you will be reminiscing of your old high school days after seeing this film. Highly recommended for both the family (since it is a very youthful but also for adults since there are many jokes that are funnier with age and experience.'\n",
            "0 b\"Alex D. Linz replaces Macaulay Culkin as the central figure in the third movie in the Home Alone empire. Four industrial spies acquire a missile guidance system computer chip and smuggle it through an airport inside a remote controlled toy car. Because of baggage confusion, grouchy Mrs. Hess (Marian Seldes) gets the car. She gives it to her neighbor, Alex (Linz), just before the spies turn up. The spies rent a house in order to burglarize each house in the neighborhood until they locate the car. Home alone with the chicken pox, Alex calls 911 each time he spots a theft in progress, but the spies always manage to elude the police while Alex is accused of making prank calls. The spies finally turn their attentions toward Alex, unaware that he has rigged devices to cleverly booby-trap his entire house. Home Alone 3 wasn't horrible, but probably shouldn't have been made, you can't just replace Macauley Culkin, Joe Pesci, or Daniel Stern. Home Alone 3 had some funny parts, but I don't like when characters are changed in a movie series, view at own risk.\"\n",
            "0 b\"There's a good movie lurking here, but this isn't it. The basic idea is good: to explore the moral issues that would face a group of young survivors of the apocalypse. But the logic is so muddled that it's impossible to get involved.<br /><br />For example, our four heroes are (understandably) paranoid about catching the mysterious airborne contagion that's wiped out virtually all of mankind. Yet they wear surgical masks some times, not others. Some times they're fanatical about wiping down with bleach any area touched by an infected person. Other times, they seem completely unconcerned.<br /><br />Worse, after apparently surviving some weeks or months in this new kill-or-be-killed world, these people constantly behave like total newbs. They don't bother accumulating proper equipment, or food. They're forever running out of fuel in the middle of nowhere. They don't take elementary precautions when meeting strangers. And after wading through the rotting corpses of the entire human race, they're as squeamish as sheltered debutantes. You have to constantly wonder how they could have survived this long... and even if they did, why anyone would want to make a movie about them.<br /><br />So when these dweebs stop to agonize over the moral dimensions of their actions, it's impossible to take their soul-searching seriously. Their actions would first have to make some kind of minimal sense.<br /><br />On top of all this, we must contend with the dubious acting abilities of Chris Pine. His portrayal of an arrogant young James T Kirk might have seemed shrewd, when viewed in isolation. But in Carriers he plays on exactly that same note: arrogant and boneheaded. It's impossible not to suspect that this constitutes his entire dramatic range.<br /><br />On the positive side, the film *looks* excellent. It's got an over-sharp, saturated look that really suits the southwestern US locale. But that can't save the truly feeble writing nor the paper-thin (and annoying) characters. Even if you're a fan of the end-of-the-world genre, you should save yourself the agony of watching Carriers.\"\n",
            "0 b'I saw this movie at an actual movie theater (probably the $2.00 one) with my cousin and uncle. We were around 11 and 12, I guess, and really into scary movies. I remember being so excited to see it because my cool uncle let us pick the movie (and we probably never got to do that again!) and sooo disappointed afterwards!! Just boring and not scary. The only redeeming thing I can remember was Corky Pigeon from Silver Spoons, and that wasn\\'t all that great, just someone I recognized. I\\'ve seen bad movies before and this one has always stuck out in my mind as the worst. This was from what I can recall, one of the most boring, non-scary, waste of our collective $6, and a waste of film. I have read some of the reviews that say it is worth a watch and I say, \"Too each his own\", but I wouldn\\'t even bother. Not even so bad it\\'s good.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBzBPY_nFLId"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
        "\n",
        ".cache() keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
        "\n",
        ".prefetch() overlaps data preprocessing and model execution while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id9bXid1DkH-"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev4jML-bJFDb"
      },
      "source": [
        "## Using the Embedding layer\n",
        "\n",
        "Keras makes it easy to use word embeddings.\n",
        "\n",
        "The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1xvreLRIrJy"
      },
      "source": [
        "# Embeded 1000 words into 5 dimesion\n",
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plmK12A7Nqow"
      },
      "source": [
        "When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBtpLKdRNrdY",
        "outputId": "fc0bf499-d261-46f0-d7cd-7a9ba5163953"
      },
      "source": [
        "# If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:\n",
        "\n",
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01419505, -0.03039126,  0.00285299,  0.01637185, -0.00406059],\n",
              "       [-0.01751189,  0.04935582,  0.0127713 ,  0.00139158,  0.03109893],\n",
              "       [-0.01356477,  0.04451648, -0.03404649,  0.0295887 , -0.04784168]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1INhW_HJO-TN"
      },
      "source": [
        "## Text preprocessing\n",
        "Next, define the dataset preprocessing steps required for your sentiment classification model. Initialize a TextVectorization layer with the desired parameters to vectorize movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCh9pDJpNvZx"
      },
      "source": [
        "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
        "def custom_standarization(imput_data):\n",
        "  lowercase = tf.strings.lower(imput_data)\n",
        "  break_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(break_html, \n",
        "                                  '[%s]' % re.escape(string.punctuation), '')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W84LxjfOP9s9"
      },
      "source": [
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to\n",
        "# integers. Note that the layer uses the custom standardization defined above.\n",
        "# Set maximum_sequence length as all samples are not of the same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standarization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length\n",
        ")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z-0tnhMQ0LO"
      },
      "source": [
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_dataset = train_dataset.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_dataset)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIHNOBe-OPQo"
      },
      "source": [
        "## Create a classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGnFR5PMOVLn"
      },
      "source": [
        "embedding_dims = 16\n",
        "model = Sequential([\n",
        "                    vectorize_layer,\n",
        "                    Embedding(vocab_size, embedding_dims, name='embedding'),\n",
        "                    GlobalAveragePooling1D(),\n",
        "                    Dense(16, activation='tanh'),\n",
        "                    tf.keras.layers.Dropout(0.5),\n",
        "                    Dense(16, activation='tanh'),\n",
        "                    tf.keras.layers.Dropout(0.5),\n",
        "                    Dense(1)\n",
        "]\n",
        ")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKIzUTCPPGZ3"
      },
      "source": [
        "## Compile and Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_wJ1C0PS0J"
      },
      "source": [
        "# Using tenorbord\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTfX19S4Pi2u"
      },
      "source": [
        "Compile and train the model using the Adam optimizer and BinaryCrossentropy loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmg24M5PmI5"
      },
      "source": [
        "model.compile(optimizer='adamax',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mWSJV1YP6DX",
        "outputId": "294171d9-c37a-4423-8959-278777ab11d8"
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=30,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "20/20 [==============================] - 4s 169ms/step - loss: 0.6930 - accuracy: 0.5037 - val_loss: 0.6923 - val_accuracy: 0.4886\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.6916 - accuracy: 0.5037 - val_loss: 0.6907 - val_accuracy: 0.4886\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 1s 76ms/step - loss: 0.6899 - accuracy: 0.5037 - val_loss: 0.6882 - val_accuracy: 0.4886\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 2s 77ms/step - loss: 0.6872 - accuracy: 0.5037 - val_loss: 0.6840 - val_accuracy: 0.4886\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.6827 - accuracy: 0.5037 - val_loss: 0.6777 - val_accuracy: 0.4886\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.6749 - accuracy: 0.5041 - val_loss: 0.6684 - val_accuracy: 0.4886\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 2s 78ms/step - loss: 0.6654 - accuracy: 0.5056 - val_loss: 0.6559 - val_accuracy: 0.4886\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.6525 - accuracy: 0.5143 - val_loss: 0.6400 - val_accuracy: 0.4968\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.6344 - accuracy: 0.5350 - val_loss: 0.6203 - val_accuracy: 0.5324\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 1s 74ms/step - loss: 0.6133 - accuracy: 0.5657 - val_loss: 0.5975 - val_accuracy: 0.5868\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.5899 - accuracy: 0.6074 - val_loss: 0.5722 - val_accuracy: 0.6374\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.5618 - accuracy: 0.6517 - val_loss: 0.5456 - val_accuracy: 0.6798\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.5351 - accuracy: 0.6919 - val_loss: 0.5189 - val_accuracy: 0.7106\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 1s 76ms/step - loss: 0.5050 - accuracy: 0.7314 - val_loss: 0.4932 - val_accuracy: 0.7414\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.4800 - accuracy: 0.7537 - val_loss: 0.4709 - val_accuracy: 0.7542\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 2s 77ms/step - loss: 0.4537 - accuracy: 0.7755 - val_loss: 0.4516 - val_accuracy: 0.7698\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 1s 75ms/step - loss: 0.4299 - accuracy: 0.7941 - val_loss: 0.4359 - val_accuracy: 0.7812\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 2s 77ms/step - loss: 0.4127 - accuracy: 0.8048 - val_loss: 0.4232 - val_accuracy: 0.7888\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.3979 - accuracy: 0.8159 - val_loss: 0.4138 - val_accuracy: 0.7920\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 2s 78ms/step - loss: 0.3827 - accuracy: 0.8265 - val_loss: 0.4052 - val_accuracy: 0.8004\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 2s 78ms/step - loss: 0.3704 - accuracy: 0.8302 - val_loss: 0.3984 - val_accuracy: 0.8056\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 2s 77ms/step - loss: 0.3577 - accuracy: 0.8397 - val_loss: 0.3930 - val_accuracy: 0.8092\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 2s 78ms/step - loss: 0.3466 - accuracy: 0.8456 - val_loss: 0.3889 - val_accuracy: 0.8150\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.3363 - accuracy: 0.8512 - val_loss: 0.3858 - val_accuracy: 0.8166\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.3289 - accuracy: 0.8565 - val_loss: 0.3832 - val_accuracy: 0.8188\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 1s 76ms/step - loss: 0.3184 - accuracy: 0.8611 - val_loss: 0.3810 - val_accuracy: 0.8200\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.3104 - accuracy: 0.8656 - val_loss: 0.3800 - val_accuracy: 0.8208\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 2s 77ms/step - loss: 0.3048 - accuracy: 0.8687 - val_loss: 0.3792 - val_accuracy: 0.8236\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.2962 - accuracy: 0.8750 - val_loss: 0.3797 - val_accuracy: 0.8218\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 2s 76ms/step - loss: 0.2900 - accuracy: 0.8775 - val_loss: 0.3802 - val_accuracy: 0.8218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL_SEe-rQQ8z"
      },
      "source": [
        "With this approach the model reaches a validation accuracy of around 84% (note that the model is overfitting since training accuracy is higher)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXCk13O4QpjY",
        "outputId": "2faaa87a-d68b-47a3-b514-c90e6bac235f"
      },
      "source": [
        "# observing the summery\n",
        "model.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_2 (TextVe (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,561\n",
            "Trainable params: 160,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OGaCyOCQ8Ie"
      },
      "source": [
        "Visualize the model metrics in TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "cfwNR6Sff0db",
        "outputId": "1f774cd9-23c6-4c8c-cd5c-41fd08610697"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd879c8d3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0yhJF_LgCe-",
        "outputId": "4b245aec-11b7-4cb0-d9da-9efd21d8efe7"
      },
      "source": [
        "dataset = [['This movie is SOOOO funny!!! The acting is WONDERFUL, the Ramones are sexy, the jokes are subtle, and the plot is just what every high schooler dreams of doing to his/her school. I absolutely loved the soundtrack as well as the carefully placed cynicism. If you like monty python, You will love this film. This movie is a tad bit \"grease\"esk (without all the annoying songs). The songs that are sung are likable; you might even find yourself singing these songs once the movie is through. This musical ranks number two in musicals to me (second next to the blues brothers). But please, do not think of it as a musical per say; seeing as how the songs are so likable, it is hard to tell a carefully choreographed scene is taking place. I think of this movie as more of a comedy with undertones of romance. You will be reminded of what it was like to be a rebellious teenager; needless to say, you will be reminiscing of your old high school days after seeing this film. Highly recommended for both the family (since it is a very youthful but also for adults since there are many jokes that are funnier with age and experience.']]\n",
        "predict = model.predict(dataset)\n",
        "\n",
        "if predict[0] > 0.5:\n",
        "  print('yes')\n",
        "else:\n",
        "  print('NO')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbh3UHRl41fQ"
      },
      "source": [
        "## Save and load model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3ado_6y41N2",
        "outputId": "f330440b-3564-458a-9c73-e2df1a21575a"
      },
      "source": [
        "export_model = 'imdb_saved_model'\n",
        "tf.saved_model.save(model, export_model)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: imdb_saved_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSCoCFCj408F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1538ce4c-03dc-4c38-dee5-2ec032484963"
      },
      "source": [
        "reloded = tf.saved_model.load(export_model)\n",
        "reloded_result = reloded(dataset, training=False)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd87b07e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd87b043830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd87d202b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fd87b5289e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k5X0oA55nYQ",
        "outputId": "02d8fca7-b8fd-4d43-916a-6702d1b2fbe9"
      },
      "source": [
        "if reloded_result[0] > 0.5:\n",
        "  print('yes')\n",
        "else:\n",
        "  print('NO')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trs1R6xPRqoL"
      },
      "source": [
        "## Retrieve the trained word embeddings and save them to disk\n",
        "\n",
        "Next, retrieve the word embeddings learned during training. The embeddings are weights of the Embedding layer in the model. The weights matrix is of shape (vocab_size, embedding_dimension).\n",
        "\n",
        "Obtain the weights from the model using get_layer() and get_weights(). The get_vocabulary() function provides the vocabulary to build a metadata file with one token per line. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alihOGdHQ-EF"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaP4-M7ERy7R"
      },
      "source": [
        "Write the weights to disk. To use the Embedding Projector, you will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PbtkLWcRzWe"
      },
      "source": [
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v74l_wqCSYOH"
      },
      "source": [
        "# try:\n",
        "  #from google.colab import files\n",
        "  #files.download('vectors.tsv')\n",
        "  #files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "  #pass\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnPf53gaSa8V"
      },
      "source": [
        ""
      ],
      "execution_count": 92,
      "outputs": []
    }
  ]
}